			+--------------------+
			|        CS 140      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Sayantan Chakraborty <sayantac@usc.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

Discussion with someone who previously took the class -- made sure to keep it to high-level questions only
Specifically, donation cases, and which data structures he would advise against modifying and why
Stack Overflow/UMich website for priority inversion details

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct list waiting;
In timer.c: sleeping threads list

int64_t start;
In thread.h: tick when sleep started

int64_t ticks;
In thread.h: tick when thread finished sleeping

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

Set start to current tick;
Disable interrupts;
If start < ticks, indicating time left for sleep;
	push to waiting list;
	block the thread

For interrupt handling:
Get the first thread on the list;
(If the thread's tick is lower or equal to start(global) tick,
it is removed and unblocked;) <-- Repeat until waiting list is empty


>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

The waiting(sleeping) list is always sorted therefore doesn't need to iterate

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

Pushing to list only happens when interrupts are disabled therefore disallowing multiple timer_sleep

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

The implementation of maintaining a sorted waiting(sleep) list reduced time spent in the interrupt handler
since it doesn't have to iterate the list everytime (that was the pseduocode I had till my friend suggested this)

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

int init_priority;
In thread.c: original priority

struct list donor_list;
In thread.c: list of threads waiting on lock the thread has

struct list_elem donor_elem;
In thread.c: element added to other threads' donor_lists'

struct lock *waiting_on_lock;
In thread.c: lock the thread is waiting on

int sema_priority;
In synch.c (added to semaphore_elem): to be able to handle condvars:
changing cond->waiters to a descending order list acc. to priority

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

For single donation, lock is acquired by the thread, if the lock
holder's priority is lower the acquirer's donation happens
If the donated thread is block by another lock, which is in the case
of nested donation - and then another donation occurs, and it will
occur again till no one who received donation is blocked by some
other thread

Thread 1 [Pri:20] [Holding LockA]
Thread 2 [Pri:40] [Holding LockB + Waiting for LockA]
Thread 3 [Pri:60] [Waiting for lock B]

In this example the thread's donation needs to not only go to the one
waiting on it but also the thread waiting on that thread.

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

get_next function iterates through the waiters list in the semaphore
and returns the thread with the highest priority

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

Update lock holder;
Donate priority to current thread if pri(holder) < pri(current);
Add itself to lock holder's donor list


>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

Set lock holder to NULL;
Do sema_up;
Set the original lock holder's priority

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

Since interrupts are not disabled in set_priority so it can cause race
conditions if there is an interrupt when the priority is being updated
to the new priority variable -- causing both to write on the priority
variable at the same time

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

I tried implementing priority donation and reverting it on synch because
I believed it made more sense but realized I would have to make more variables,
so I moved to a more ad-hoc implementation, which I believe is worse semantically
but does work and pass the test cases. If given a chance, I'd like to see
how my previous design would have fared to the current one (since I believe it may
have actually been easier)

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

It took a while to get started, but that was mostly due to getting started
with Pintos itself.

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

This assignment as a whole did do so since threads are an integral part of
an operating system. And since all these new processors are coming out in the
market boasting raging number of cores, it makes me appreciate the complexity
and the amount of effort that is put into the development of an OS being able
to support varying processors while prioritizing and switching seamlessly
(for the most bit)

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

The Pintos Guide was the most helpful resource

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

More spread out OH would be great

>> Any other comments?

No
